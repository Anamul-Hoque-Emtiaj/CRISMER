{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b285a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:51.295051Z",
     "iopub.status.busy": "2024-11-25T12:46:51.294305Z",
     "iopub.status.idle": "2024-11-25T12:46:54.355375Z",
     "shell.execute_reply": "2024-11-25T12:46:54.354697Z"
    },
    "papermill": {
     "duration": 3.066688,
     "end_time": "2024-11-25T12:46:54.357363",
     "exception": false,
     "start_time": "2024-11-25T12:46:51.290675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "seed = 12345\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183d8f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.364912Z",
     "iopub.status.busy": "2024-11-25T12:46:54.364573Z",
     "iopub.status.idle": "2024-11-25T12:46:54.424467Z",
     "shell.execute_reply": "2024-11-25T12:46:54.423648Z"
    },
    "papermill": {
     "duration": 0.065408,
     "end_time": "2024-11-25T12:46:54.426120",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.360712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c8b5c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.433416Z",
     "iopub.status.busy": "2024-11-25T12:46:54.433161Z",
     "iopub.status.idle": "2024-11-25T12:46:54.441144Z",
     "shell.execute_reply": "2024-11-25T12:46:54.440455Z"
    },
    "papermill": {
     "duration": 0.013319,
     "end_time": "2024-11-25T12:46:54.442616",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.429297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, kernel_size=1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, kernel_size=1, bias=False)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        assert kernel_size in (3, 7), 'Kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980c5e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.451039Z",
     "iopub.status.busy": "2024-11-25T12:46:54.450804Z",
     "iopub.status.idle": "2024-11-25T12:46:54.460949Z",
     "shell.execute_reply": "2024-11-25T12:46:54.460381Z"
    },
    "papermill": {
     "duration": 0.015698,
     "end_time": "2024-11-25T12:46:54.462449",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.446751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiBranchConv(nn.Module):\n",
    "    def __init__(self, output_channels=16, attention=True):\n",
    "        super(MultiBranchConv, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Conv2d(in_channels=1, out_channels=output_channels, kernel_size=(1, 16))\n",
    "        self.branch2 = nn.Conv2d(in_channels=1, out_channels=output_channels, kernel_size=(2, 16))\n",
    "        self.branch3 = nn.Conv2d(in_channels=1, out_channels=output_channels, kernel_size=(3, 16))\n",
    "        self.branch4 = nn.Conv2d(in_channels=1, out_channels=output_channels, kernel_size=(4, 16))\n",
    "        \n",
    "        self.attn = attention\n",
    "        self.ca1 = ChannelAttention(output_channels)\n",
    "        self.ca2 = ChannelAttention(output_channels)\n",
    "        self.ca3 = ChannelAttention(output_channels)\n",
    "        self.ca4 = ChannelAttention(output_channels)\n",
    "        self.sa1 = SpatialAttention(kernel_size=7)\n",
    "        self.sa2 = SpatialAttention(kernel_size=7)\n",
    "        self.sa3 = SpatialAttention(kernel_size=7)\n",
    "        self.sa4 = SpatialAttention(kernel_size=7)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Branch 1: No padding needed\n",
    "        out1 = F.relu(self.branch1(x))\n",
    "\n",
    "        # Branch 2: Pad to the right (end)\n",
    "        x_pad2 = F.pad(x, (0, 0, 0, 1))  # Padding only at the end (on the height dimension)\n",
    "        out2 = F.relu(self.branch2(x_pad2))\n",
    "\n",
    "        # Branch 3: Pad one row at the beginning and one at the end\n",
    "        x_pad3 = F.pad(x, (0, 0, 1, 1))  # One padding at the start and one at the end\n",
    "        out3 = F.relu(self.branch3(x_pad3))\n",
    "\n",
    "        # Branch 4: Pad two rows at the beginning and one at the end\n",
    "        x_pad4 = F.pad(x, (0, 0, 1, 2))  # One at the start, Two at the end\n",
    "        out4 = F.relu(self.branch4(x_pad4))\n",
    "\n",
    "        # Apply attention if enabled\n",
    "        if self.attn:\n",
    "            out1 = out1 * self.ca1(out1)\n",
    "            out1 = out1 * self.sa1(out1)\n",
    "\n",
    "            out2 = out2 * self.ca2(out2)\n",
    "            out2 = out2 * self.sa2(out2)\n",
    "\n",
    "            out3 = out3 * self.ca3(out3)\n",
    "            out3 = out3 * self.sa3(out3)\n",
    "\n",
    "            out4 = out4 * self.ca4(out4)\n",
    "            out4 = out4 * self.sa4(out4)\n",
    "\n",
    "        # Remove last dimension of size 1 (from Conv2D)\n",
    "        out1 = out1.squeeze(-1)\n",
    "        out2 = out2.squeeze(-1)\n",
    "        out3 = out3.squeeze(-1)\n",
    "        out4 = out4.squeeze(-1)\n",
    "\n",
    "        # Transpose for concatenation later\n",
    "        out1 = out1.transpose(1, 2)\n",
    "        out2 = out2.transpose(1, 2)\n",
    "        out3 = out3.transpose(1, 2)\n",
    "        out4 = out4.transpose(1, 2)\n",
    "\n",
    "        # Concatenate along the last dimension\n",
    "        output = torch.cat((out1, out2, out3, out4), dim=-1)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8577851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.469532Z",
     "iopub.status.busy": "2024-11-25T12:46:54.469266Z",
     "iopub.status.idle": "2024-11-25T12:46:54.477251Z",
     "shell.execute_reply": "2024-11-25T12:46:54.476558Z"
    },
    "papermill": {
     "duration": 0.013309,
     "end_time": "2024-11-25T12:46:54.478876",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.465567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class CRISPRTransformerModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CRISPRTransformerModel, self).__init__()\n",
    "        \n",
    "        # Model parameters\n",
    "        self.input_dim = 64\n",
    "        self.num_layers = config.get(\"num_layers\", 2)\n",
    "        self.num_heads = config.get(\"num_heads\", 8)\n",
    "        self.dropout_prob = config[\"dropout_prob\"]\n",
    "        self.number_hidden_layers = config[\"number_hidder_layers\"]\n",
    "        self.seq_length = config.get(\"seq_length\", 23)\n",
    "        \n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoder = nn.Parameter(torch.randn(1, self.seq_length, self.input_dim))\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.input_dim,\n",
    "            nhead=self.num_heads,\n",
    "            dim_feedforward=self.input_dim * 4,\n",
    "            dropout=self.dropout_prob,\n",
    "            batch_first=True,\n",
    "            norm_first=True  \n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "        \n",
    "        # Convolutional preprocessing\n",
    "        self.conv = MultiBranchConv(attention=config[\"attn\"])\n",
    "        \n",
    "        # Hidden layers\n",
    "        self.hidden_layers = []\n",
    "        start_size = self.seq_length*self.input_dim\n",
    "        for i in range(self.number_hidden_layers):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Linear(start_size, start_size // 2),\n",
    "                nn.GELU(),  \n",
    "                nn.Dropout(self.dropout_prob)\n",
    "            )\n",
    "            self.hidden_layers.append(layer)\n",
    "            start_size = start_size // 2\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Linear(start_size, 2)\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        # Apply conv layer\n",
    "        x = self.conv(x)  # Shape: [batch_size, seq_len, input_dim]\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.pos_encoder\n",
    "        \n",
    "        # Apply transformer encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994fad1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.486069Z",
     "iopub.status.busy": "2024-11-25T12:46:54.485639Z",
     "iopub.status.idle": "2024-11-25T12:46:54.490139Z",
     "shell.execute_reply": "2024-11-25T12:46:54.489528Z"
    },
    "papermill": {
     "duration": 0.009626,
     "end_time": "2024-11-25T12:46:54.491636",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.482010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class TrainerDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7759103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.499103Z",
     "iopub.status.busy": "2024-11-25T12:46:54.498471Z",
     "iopub.status.idle": "2024-11-25T12:46:54.504556Z",
     "shell.execute_reply": "2024-11-25T12:46:54.503806Z"
    },
    "papermill": {
     "duration": 0.011241,
     "end_time": "2024-11-25T12:46:54.506078",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.494837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_model(model, train_loader, optimizer, scheduler, criterion, device, num_epochs):\n",
    "    model = model.to(device)\n",
    "    history = {'train_loss': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Training loop\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Loss tracking\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Average loss for the epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f}\")\n",
    "        scheduler.step()\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5032beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.513646Z",
     "iopub.status.busy": "2024-11-25T12:46:54.513191Z",
     "iopub.status.idle": "2024-11-25T12:46:54.518847Z",
     "shell.execute_reply": "2024-11-25T12:46:54.518086Z"
    },
    "papermill": {
     "duration": 0.010894,
     "end_time": "2024-11-25T12:46:54.520381",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.509487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainer(config, train_x, train_y):\n",
    "    seed = 12345\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    train_dataset = TrainerDataset(train_x, train_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    model = CRISPRTransformerModel(config)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    class_weights = torch.tensor([1.0, config['pos_weight']]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    trained_model, history = train_model(model, train_loader, optimizer, scheduler, criterion, device, config['epochs'])\n",
    "    return trained_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22faae96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.527944Z",
     "iopub.status.busy": "2024-11-25T12:46:54.527328Z",
     "iopub.status.idle": "2024-11-25T12:46:54.532032Z",
     "shell.execute_reply": "2024-11-25T12:46:54.531292Z"
    },
    "papermill": {
     "duration": 0.009919,
     "end_time": "2024-11-25T12:46:54.533513",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.523594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tester(model, test_x, test_y):\n",
    "    test_dataset = TrainerDataset(test_x, test_y)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    model.eval()\n",
    "    results = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for test_features, test_labels in test_dataloader:\n",
    "            outputs = model(test_features.to(device)).detach().to(\"cpu\")\n",
    "            results.extend(outputs)\n",
    "            true_labels.extend(test_labels)\n",
    "    return true_labels, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ee7c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.540929Z",
     "iopub.status.busy": "2024-11-25T12:46:54.540479Z",
     "iopub.status.idle": "2024-11-25T12:46:54.545555Z",
     "shell.execute_reply": "2024-11-25T12:46:54.544788Z"
    },
    "papermill": {
     "duration": 0.010419,
     "end_time": "2024-11-25T12:46:54.547174",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.536755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Stats:\n",
    "    def __init__(self):\n",
    "        self.acc = 0\n",
    "        self.pre = 0\n",
    "        self.re = 0\n",
    "        self.f1 = 0\n",
    "        self.roc = 0\n",
    "        self.prc = 0\n",
    "        self.tn = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        self.tp = 0\n",
    "    def print(self):\n",
    "        print('Accuracy: %.4f' %self.acc)\n",
    "        print('Precision: %.4f' %self.pre)\n",
    "        print('Recall: %.4f' %self.re)\n",
    "        print('F1 Score: %.4f' %self.f1)\n",
    "        print('ROC: %.4f' %self.roc)\n",
    "        print('PR AUC: %.4f' %self.prc)\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(self.tn, \"\\t\", self.fp)\n",
    "        print(self.fn, \"\\t\", self.tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cab653e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:54.554712Z",
     "iopub.status.busy": "2024-11-25T12:46:54.554273Z",
     "iopub.status.idle": "2024-11-25T12:46:55.594168Z",
     "shell.execute_reply": "2024-11-25T12:46:55.593379Z"
    },
    "papermill": {
     "duration": 1.045693,
     "end_time": "2024-11-25T12:46:55.596114",
     "exception": false,
     "start_time": "2024-11-25T12:46:54.550421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_matrices(model, test_x, test_y, debug = True):\n",
    "    true_y, results = tester(model, test_x, test_y)\n",
    "    predictions = [torch.nn.functional.softmax(r) for r in results]\n",
    "    pred_y = np.array([y[1].item() for y in predictions])\n",
    "    pred_y_list = []\n",
    "    test_y = np.array([y.item() for y in true_y])\n",
    "\n",
    "    for x in pred_y:\n",
    "        if(x>0.5):\n",
    "            pred_y_list.append(1)\n",
    "        else:\n",
    "            pred_y_list.append(0)\n",
    "\n",
    "    pred_y_list = np.array(pred_y_list)\n",
    "    tn, fp, fn, tp = confusion_matrix(test_y, pred_y_list).ravel()\n",
    "    precision, recall, _ = precision_recall_curve(test_y, pred_y)\n",
    "    auc_score = auc(recall, precision)\n",
    "    acc = accuracy_score(test_y, pred_y_list)\n",
    "\n",
    "    pr = -1\n",
    "    re = -1\n",
    "    f1 = -1\n",
    "    try:\n",
    "        pr = tp / (tp+fp)\n",
    "        re = tp / (tp+fn)\n",
    "        f1 = 2*pr*re / (pr+re)\n",
    "    except:\n",
    "        f1 = -1\n",
    "\n",
    "    stats = Stats()\n",
    "    stats.acc = acc\n",
    "    stats.pre = pr\n",
    "    stats.re = re\n",
    "    stats.f1 = f1\n",
    "    stats.roc = roc_auc_score(test_y, pred_y)\n",
    "    stats.prc = auc_score\n",
    "    stats.tn = tn\n",
    "    stats.fp = fp\n",
    "    stats.fn = fn\n",
    "    stats.tp = tp\n",
    "\n",
    "    if debug:\n",
    "        print('Accuracy: %.4f' %acc)\n",
    "        print('Precision: %.4f' %pr)\n",
    "        print('Recall: %.4f' %re)\n",
    "        print('F1 Score: %.4f' %f1)\n",
    "        print('ROC:',roc_auc_score(test_y, pred_y))\n",
    "        print('PR AUC: %.4f' % auc_score)\n",
    "\n",
    "        # print(classification_report(test_y, pred_y_list, digits=4))\n",
    "        # print(\"Confusion Matrix\")\n",
    "        # print(confusion_matrix(test_y, pred_y_list))\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe11e0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:55.606213Z",
     "iopub.status.busy": "2024-11-25T12:46:55.605116Z",
     "iopub.status.idle": "2024-11-25T12:46:55.611627Z",
     "shell.execute_reply": "2024-11-25T12:46:55.610793Z"
    },
    "papermill": {
     "duration": 0.012384,
     "end_time": "2024-11-25T12:46:55.613294",
     "exception": false,
     "start_time": "2024-11-25T12:46:55.600910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_features(df):\n",
    "    print(\"Generating One hot encoding features...\")\n",
    "    \n",
    "    # Nucleotides and possible pairs\n",
    "    nucleotides = ['A', 'T', 'G', 'C']\n",
    "    pairs = [f'{n1}{n2}' for n1 in nucleotides for n2 in nucleotides]  # 16 possible pairs\n",
    "    \n",
    "    # Initialize the pairwise feature matrix (rows = positions, columns = 16 pairs)\n",
    "    pairwise_features = np.zeros((len(df), 23, len(pairs)))  # (samples, positions=23, pairs=16)\n",
    "    \n",
    "    # Loop through each row in the DataFrame and populate the pairwise features\n",
    "    for idx, row in df.iterrows():\n",
    "        on_seq = row['Target sgRNA']\n",
    "        off_seq = row['Off Target sgRNA']\n",
    "        \n",
    "        for pos in range(23):  # Loop through positions 1 to 23\n",
    "            pair = on_seq[pos] + off_seq[pos]  # Create the pair from the same position in both sequences\n",
    "            if pair in pairs:\n",
    "                pair_idx = pairs.index(pair)  # Get the index of the pair\n",
    "                pairwise_features[idx, pos, pair_idx] = 1  # Set the feature value to 1\n",
    "    \n",
    "    # Return a DataFrame with the pairwise features\n",
    "    # Reshape to (len(df), 23, 16) as the final output\n",
    "    return pairwise_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede7850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:55.620762Z",
     "iopub.status.busy": "2024-11-25T12:46:55.620477Z",
     "iopub.status.idle": "2024-11-25T12:46:55.916901Z",
     "shell.execute_reply": "2024-11-25T12:46:55.915941Z"
    },
    "papermill": {
     "duration": 0.302435,
     "end_time": "2024-11-25T12:46:55.919022",
     "exception": false,
     "start_time": "2024-11-25T12:46:55.616587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data_path = \"datasets/all_off_target.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "train_data, test_data = train_test_split(df, stratify=df['label'], test_size=0.20, random_state=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93260b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:55.927901Z",
     "iopub.status.busy": "2024-11-25T12:46:55.927198Z",
     "iopub.status.idle": "2024-11-25T12:46:55.934518Z",
     "shell.execute_reply": "2024-11-25T12:46:55.933698Z"
    },
    "papermill": {
     "duration": 0.013354,
     "end_time": "2024-11-25T12:46:55.936200",
     "exception": false,
     "start_time": "2024-11-25T12:46:55.922846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f3148b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:46:55.944750Z",
     "iopub.status.busy": "2024-11-25T12:46:55.944058Z",
     "iopub.status.idle": "2024-11-25T12:47:05.336621Z",
     "shell.execute_reply": "2024-11-25T12:47:05.335886Z"
    },
    "papermill": {
     "duration": 9.398913,
     "end_time": "2024-11-25T12:47:05.338633",
     "exception": false,
     "start_time": "2024-11-25T12:46:55.939720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating One hot encoding features...\n",
      "Generating One hot encoding features...\n"
     ]
    }
   ],
   "source": [
    "train_x = one_hot_features(train_data)\n",
    "test_x = one_hot_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e73860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:47:05.347643Z",
     "iopub.status.busy": "2024-11-25T12:47:05.347104Z",
     "iopub.status.idle": "2024-11-25T12:47:05.351157Z",
     "shell.execute_reply": "2024-11-25T12:47:05.350523Z"
    },
    "papermill": {
     "duration": 0.010289,
     "end_time": "2024-11-25T12:47:05.352762",
     "exception": false,
     "start_time": "2024-11-25T12:47:05.342473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_y = train_data['label'].to_numpy()\n",
    "test_y = test_data['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8760a1eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:47:05.361022Z",
     "iopub.status.busy": "2024-11-25T12:47:05.360774Z",
     "iopub.status.idle": "2024-11-25T13:01:29.944005Z",
     "shell.execute_reply": "2024-11-25T13:01:29.942915Z"
    },
    "papermill": {
     "duration": 864.589349,
     "end_time": "2024-11-25T13:01:29.945813",
     "exception": false,
     "start_time": "2024-11-25T12:47:05.356464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 | Train Loss: 0.1600\n",
      "Epoch 2/40 | Train Loss: 0.1311\n",
      "Epoch 3/40 | Train Loss: 0.1063\n",
      "Epoch 4/40 | Train Loss: 0.0833\n",
      "Epoch 5/40 | Train Loss: 0.0711\n",
      "Epoch 6/40 | Train Loss: 0.0612\n",
      "Epoch 7/40 | Train Loss: 0.0530\n",
      "Epoch 8/40 | Train Loss: 0.0491\n",
      "Epoch 9/40 | Train Loss: 0.0451\n",
      "Epoch 10/40 | Train Loss: 0.0443\n",
      "Epoch 11/40 | Train Loss: 0.0527\n",
      "Epoch 12/40 | Train Loss: 0.0485\n",
      "Epoch 13/40 | Train Loss: 0.0453\n",
      "Epoch 14/40 | Train Loss: 0.0420\n",
      "Epoch 15/40 | Train Loss: 0.0392\n",
      "Epoch 16/40 | Train Loss: 0.0369\n",
      "Epoch 17/40 | Train Loss: 0.0359\n",
      "Epoch 18/40 | Train Loss: 0.0335\n",
      "Epoch 19/40 | Train Loss: 0.0317\n",
      "Epoch 20/40 | Train Loss: 0.0284\n",
      "Epoch 21/40 | Train Loss: 0.0275\n",
      "Epoch 22/40 | Train Loss: 0.0264\n",
      "Epoch 23/40 | Train Loss: 0.0244\n",
      "Epoch 24/40 | Train Loss: 0.0237\n",
      "Epoch 25/40 | Train Loss: 0.0221\n",
      "Epoch 26/40 | Train Loss: 0.0211\n",
      "Epoch 27/40 | Train Loss: 0.0209\n",
      "Epoch 28/40 | Train Loss: 0.0194\n",
      "Epoch 29/40 | Train Loss: 0.0200\n",
      "Epoch 30/40 | Train Loss: 0.0189\n",
      "Epoch 31/40 | Train Loss: 0.0284\n",
      "Epoch 32/40 | Train Loss: 0.0288\n",
      "Epoch 33/40 | Train Loss: 0.0274\n",
      "Epoch 34/40 | Train Loss: 0.0236\n",
      "Epoch 35/40 | Train Loss: 0.0237\n",
      "Epoch 36/40 | Train Loss: 0.0240\n",
      "Epoch 37/40 | Train Loss: 0.0202\n",
      "Epoch 38/40 | Train Loss: 0.0213\n",
      "Epoch 39/40 | Train Loss: 0.0198\n",
      "Epoch 40/40 | Train Loss: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1950465590.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = [torch.nn.functional.softmax(r) for r in results]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9973\n",
      "Precision: 0.6623\n",
      "Recall: 0.7634\n",
      "F1 Score: 0.7092\n",
      "ROC: 0.9923779191293968\n",
      "PR AUC: 0.8006\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_layers': 2,\n",
    "    'num_heads': 4, \n",
    "    'number_hidder_layers': 1, \n",
    "    'dropout_prob': 0.2, \n",
    "    'batch_size': 64, \n",
    "    'epochs': 40, \n",
    "    'learning_rate': 0.0001, \n",
    "    'pos_weight': 10, \n",
    "    'attn': True\n",
    "}\n",
    "model, history = trainer(config, train_x, train_y)\n",
    "stats = eval_matrices(model, test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4146873,
     "sourceId": 9854599,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 883.922381,
   "end_time": "2024-11-25T13:01:32.145443",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-25T12:46:48.223062",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
