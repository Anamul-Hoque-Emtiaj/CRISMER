{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a1920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:36.439730Z",
     "iopub.status.busy": "2024-12-07T06:53:36.438966Z",
     "iopub.status.idle": "2024-12-07T06:53:39.541322Z",
     "shell.execute_reply": "2024-12-07T06:53:39.540612Z"
    },
    "papermill": {
     "duration": 3.107939,
     "end_time": "2024-12-07T06:53:39.543314",
     "exception": false,
     "start_time": "2024-12-07T06:53:36.435375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "seed = 12345\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a037375d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:39.550582Z",
     "iopub.status.busy": "2024-12-07T06:53:39.550203Z",
     "iopub.status.idle": "2024-12-07T06:53:39.612715Z",
     "shell.execute_reply": "2024-12-07T06:53:39.611766Z"
    },
    "papermill": {
     "duration": 0.067921,
     "end_time": "2024-12-07T06:53:39.614446",
     "exception": false,
     "start_time": "2024-12-07T06:53:39.546525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660002c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:39.621602Z",
     "iopub.status.busy": "2024-12-07T06:53:39.621193Z",
     "iopub.status.idle": "2024-12-07T06:53:39.629810Z",
     "shell.execute_reply": "2024-12-07T06:53:39.629001Z"
    },
    "papermill": {
     "duration": 0.01382,
     "end_time": "2024-12-07T06:53:39.631343",
     "exception": false,
     "start_time": "2024-12-07T06:53:39.617523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, kernel_size=1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, kernel_size=1, bias=False)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        assert kernel_size in (3, 7), 'Kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b711714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:39.638201Z",
     "iopub.status.busy": "2024-12-07T06:53:39.637943Z",
     "iopub.status.idle": "2024-12-07T06:53:39.647749Z",
     "shell.execute_reply": "2024-12-07T06:53:39.646980Z"
    },
    "papermill": {
     "duration": 0.015265,
     "end_time": "2024-12-07T06:53:39.649417",
     "exception": false,
     "start_time": "2024-12-07T06:53:39.634152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiBranchConv(nn.Module):\n",
    "    def __init__(self, output_channels=16, attention=True):\n",
    "        super(MultiBranchConv, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Conv2d(in_channels=1, out_channels=output_channels, kernel_size=(1, 16))\n",
    "        self.branch2 = nn.Conv2d(in_channels=1, out_channels=output_channels, kernel_size=(2, 16))\n",
    "        self.branch3 = nn.Conv2d(in_channels=1, out_channels=output_channels, kernel_size=(3, 16))\n",
    "        self.branch4 = nn.Conv2d(in_channels=1, out_channels=output_channels, kernel_size=(4, 16))\n",
    "        \n",
    "        self.attn = attention\n",
    "        self.ca1 = ChannelAttention(output_channels)\n",
    "        self.ca2 = ChannelAttention(output_channels)\n",
    "        self.ca3 = ChannelAttention(output_channels)\n",
    "        self.ca4 = ChannelAttention(output_channels)\n",
    "        self.sa1 = SpatialAttention(kernel_size=7)\n",
    "        self.sa2 = SpatialAttention(kernel_size=7)\n",
    "        self.sa3 = SpatialAttention(kernel_size=7)\n",
    "        self.sa4 = SpatialAttention(kernel_size=7)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Branch 1: No padding needed\n",
    "        out1 = F.relu(self.branch1(x))\n",
    "\n",
    "        # Branch 2: Pad to the right (end) \n",
    "        x_pad2 = F.pad(x, (0, 0, 0, 1))  # Padding only at the end (on the height dimension)\n",
    "        out2 = F.relu(self.branch2(x_pad2))\n",
    "\n",
    "        # Branch 3: Pad one row at the beginning and one at the end\n",
    "        x_pad3 = F.pad(x, (0, 0, 1, 1))  # One padding at the start and one at the end\n",
    "        out3 = F.relu(self.branch3(x_pad3))\n",
    "\n",
    "        # Branch 4: Pad two rows at the beginning and one at the end\n",
    "        x_pad4 = F.pad(x, (0, 0, 1, 2))  # One at the start, Two at the end\n",
    "        out4 = F.relu(self.branch4(x_pad4))\n",
    "\n",
    "        # Apply attention if enabled\n",
    "        if self.attn:\n",
    "            out1 = out1 * self.ca1(out1)\n",
    "            out1 = out1 * self.sa1(out1)\n",
    "\n",
    "            out2 = out2 * self.ca2(out2)\n",
    "            out2 = out2 * self.sa2(out2)\n",
    "\n",
    "            out3 = out3 * self.ca3(out3)\n",
    "            out3 = out3 * self.sa3(out3)\n",
    "\n",
    "            out4 = out4 * self.ca4(out4)\n",
    "            out4 = out4 * self.sa4(out4)\n",
    "\n",
    "        # Remove last dimension of size 1 (from Conv2D)\n",
    "        out1 = out1.squeeze(-1)\n",
    "        out2 = out2.squeeze(-1)\n",
    "        out3 = out3.squeeze(-1)\n",
    "        out4 = out4.squeeze(-1)\n",
    "\n",
    "        # Transpose for concatenation later\n",
    "        out1 = out1.transpose(1, 2)\n",
    "        out2 = out2.transpose(1, 2)\n",
    "        out3 = out3.transpose(1, 2)\n",
    "        out4 = out4.transpose(1, 2)\n",
    "\n",
    "        # Concatenate along the last dimension\n",
    "        output = torch.cat((out1, out2, out3, out4), dim=-1)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700515e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:39.657514Z",
     "iopub.status.busy": "2024-12-07T06:53:39.656980Z",
     "iopub.status.idle": "2024-12-07T06:53:39.665316Z",
     "shell.execute_reply": "2024-12-07T06:53:39.664532Z"
    },
    "papermill": {
     "duration": 0.013625,
     "end_time": "2024-12-07T06:53:39.666952",
     "exception": false,
     "start_time": "2024-12-07T06:53:39.653327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class CRISPRTransformerModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CRISPRTransformerModel, self).__init__()\n",
    "        \n",
    "        # Model parameters\n",
    "        self.input_dim = 64\n",
    "        self.num_layers = config.get(\"num_layers\", 2)\n",
    "        self.num_heads = config.get(\"num_heads\", 8)\n",
    "        self.dropout_prob = config[\"dropout_prob\"]\n",
    "        self.number_hidden_layers = config[\"number_hidder_layers\"]\n",
    "        self.seq_length = config.get(\"seq_length\", 20)\n",
    "        \n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoder = nn.Parameter(torch.randn(1, self.seq_length, self.input_dim))\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.input_dim,\n",
    "            nhead=self.num_heads,\n",
    "            dim_feedforward=self.input_dim * 4,\n",
    "            dropout=self.dropout_prob,\n",
    "            batch_first=True,\n",
    "            norm_first=True  \n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "        \n",
    "        # Convolutional preprocessing\n",
    "        self.conv = MultiBranchConv(attention=config[\"attn\"])\n",
    "        \n",
    "        # Hidden layers\n",
    "        self.hidden_layers = []\n",
    "        start_size = self.seq_length*self.input_dim\n",
    "        for i in range(self.number_hidden_layers):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Linear(start_size, start_size // 2),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(self.dropout_prob)\n",
    "            )\n",
    "            self.hidden_layers.append(layer)\n",
    "            start_size = start_size // 2\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Linear(start_size, 2)\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        # Apply conv layer\n",
    "        x = self.conv(x)  # Shape: [batch_size, seq_len, input_dim]\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.pos_encoder\n",
    "        \n",
    "        # Apply transformer encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0575dc5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:39.673731Z",
     "iopub.status.busy": "2024-12-07T06:53:39.673481Z",
     "iopub.status.idle": "2024-12-07T06:53:39.678350Z",
     "shell.execute_reply": "2024-12-07T06:53:39.677627Z"
    },
    "papermill": {
     "duration": 0.010113,
     "end_time": "2024-12-07T06:53:39.679917",
     "exception": false,
     "start_time": "2024-12-07T06:53:39.669804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class TrainerDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1841dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:39.686915Z",
     "iopub.status.busy": "2024-12-07T06:53:39.686674Z",
     "iopub.status.idle": "2024-12-07T06:53:39.691173Z",
     "shell.execute_reply": "2024-12-07T06:53:39.690546Z"
    },
    "papermill": {
     "duration": 0.009724,
     "end_time": "2024-12-07T06:53:39.692636",
     "exception": false,
     "start_time": "2024-12-07T06:53:39.682912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tester(model, test_x, test_y):\n",
    "    test_dataset = TrainerDataset(test_x, test_y)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    model.eval()\n",
    "    results = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for test_features, test_labels in test_dataloader:\n",
    "            outputs = model(test_features.to(device)).detach().to(\"cpu\")\n",
    "            results.extend(outputs)\n",
    "            true_labels.extend(test_labels)\n",
    "    return true_labels, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d75cbcd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:39.699342Z",
     "iopub.status.busy": "2024-12-07T06:53:39.699103Z",
     "iopub.status.idle": "2024-12-07T06:53:39.704214Z",
     "shell.execute_reply": "2024-12-07T06:53:39.703438Z"
    },
    "papermill": {
     "duration": 0.010202,
     "end_time": "2024-12-07T06:53:39.705764",
     "exception": false,
     "start_time": "2024-12-07T06:53:39.695562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Stats:\n",
    "    def __init__(self):\n",
    "        self.acc = 0\n",
    "        self.pre = 0\n",
    "        self.re = 0\n",
    "        self.f1 = 0\n",
    "        self.roc = 0\n",
    "        self.prc = 0\n",
    "        self.tn = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        self.tp = 0\n",
    "    def print(self):\n",
    "        print('Accuracy: %.4f' %self.acc)\n",
    "        print('Precision: %.4f' %self.pre)\n",
    "        print('Recall: %.4f' %self.re)\n",
    "        print('F1 Score: %.4f' %self.f1)\n",
    "        print('ROC: %.4f' %self.roc)\n",
    "        print('PR AUC: %.4f' %self.prc)\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(self.tn, \"\\t\", self.fp)\n",
    "        print(self.fn, \"\\t\", self.tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de82991b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:39.712673Z",
     "iopub.status.busy": "2024-12-07T06:53:39.712379Z",
     "iopub.status.idle": "2024-12-07T06:53:40.779345Z",
     "shell.execute_reply": "2024-12-07T06:53:40.778437Z"
    },
    "papermill": {
     "duration": 1.072663,
     "end_time": "2024-12-07T06:53:40.781436",
     "exception": false,
     "start_time": "2024-12-07T06:53:39.708773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_matrices(model, test_x, test_y, debug = True):\n",
    "    true_y, results = tester(model, test_x, test_y)\n",
    "    predictions = [torch.nn.functional.softmax(r) for r in results]\n",
    "    pred_y = np.array([y[1].item() for y in predictions])\n",
    "    pred_y_list = []\n",
    "    test_y = np.array([y.item() for y in true_y])\n",
    "\n",
    "    for x in pred_y:\n",
    "        if(x>0.5):\n",
    "            pred_y_list.append(1)\n",
    "        else:\n",
    "            pred_y_list.append(0)\n",
    "\n",
    "    pred_y_list = np.array(pred_y_list)\n",
    "    tn, fp, fn, tp = confusion_matrix(test_y, pred_y_list).ravel()\n",
    "    precision, recall, _ = precision_recall_curve(test_y, pred_y)\n",
    "    auc_score = auc(recall, precision)\n",
    "    acc = accuracy_score(test_y, pred_y_list)\n",
    "\n",
    "    pr = -1\n",
    "    re = -1\n",
    "    f1 = -1\n",
    "    try:\n",
    "        pr = tp / (tp+fp)\n",
    "        re = tp / (tp+fn)\n",
    "        f1 = 2*pr*re / (pr+re)\n",
    "    except:\n",
    "        f1 = -1\n",
    "\n",
    "    stats = Stats()\n",
    "    stats.acc = acc\n",
    "    stats.pre = pr\n",
    "    stats.re = re\n",
    "    stats.f1 = f1\n",
    "    stats.roc = roc_auc_score(test_y, pred_y)\n",
    "    stats.prc = auc_score\n",
    "    stats.tn = tn\n",
    "    stats.fp = fp\n",
    "    stats.fn = fn\n",
    "    stats.tp = tp\n",
    "\n",
    "    if debug:\n",
    "        print('Accuracy: %.4f' %acc)\n",
    "        print('Precision: %.4f' %pr)\n",
    "        print('Recall: %.4f' %re)\n",
    "        print('F1 Score: %.4f' %f1)\n",
    "        print('ROC:',roc_auc_score(test_y, pred_y))\n",
    "        print('PR AUC: %.4f' % auc_score)\n",
    "\n",
    "        # print(classification_report(test_y, pred_y_list, digits=4))\n",
    "        # print(\"Confusion Matrix\")\n",
    "        # print(confusion_matrix(test_y, pred_y_list))\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce1183a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:40.789775Z",
     "iopub.status.busy": "2024-12-07T06:53:40.789345Z",
     "iopub.status.idle": "2024-12-07T06:53:40.795505Z",
     "shell.execute_reply": "2024-12-07T06:53:40.794758Z"
    },
    "papermill": {
     "duration": 0.012145,
     "end_time": "2024-12-07T06:53:40.797122",
     "exception": false,
     "start_time": "2024-12-07T06:53:40.784977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def one_hot_features(df):\n",
    "    print(\"Generating One hot encoding features...\")\n",
    "    \n",
    "    # Nucleotides and possible pairs\n",
    "    nucleotides = ['A', 'T', 'G', 'C']\n",
    "    pairs = [f'{n1}{n2}' for n1 in nucleotides for n2 in nucleotides]  # 16 possible pairs\n",
    "    \n",
    "    # Initialize the pairwise feature matrix (rows = positions, columns = 16 pairs)\n",
    "    pairwise_features = np.zeros((len(df), 20, len(pairs)))  # (samples, positions=20, pairs=16)\n",
    "    \n",
    "    # Loop through each row in the DataFrame and populate the pairwise features\n",
    "    for idx, row in df.iterrows():\n",
    "        on_seq = row['On']\n",
    "        off_seq = row['Off']\n",
    "        \n",
    "        for pos in range(20):  # Loop through positions 1 to 20\n",
    "            pair = on_seq[pos] + off_seq[pos]  # Create the pair from the same position in both sequences\n",
    "            if pair in pairs:\n",
    "                pair_idx = pairs.index(pair)  # Get the index of the pair\n",
    "                pairwise_features[idx, pos, pair_idx] = 1  # Set the feature value to 1\n",
    "    \n",
    "    # Return a DataFrame with the pairwise features\n",
    "    # Reshape to (len(df), 20, 16) as the final output\n",
    "    return pairwise_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7759e794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:40.804136Z",
     "iopub.status.busy": "2024-12-07T06:53:40.803910Z",
     "iopub.status.idle": "2024-12-07T06:53:40.809998Z",
     "shell.execute_reply": "2024-12-07T06:53:40.809238Z"
    },
    "papermill": {
     "duration": 0.012373,
     "end_time": "2024-12-07T06:53:40.812501",
     "exception": false,
     "start_time": "2024-12-07T06:53:40.800128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval(model):\n",
    "    print(\"Circleseq\")\n",
    "    data_path = \"datasets/circleseq_all.csv\"\n",
    "    test_data = pd.read_csv(data_path)\n",
    "    test_x = one_hot_features(test_data)\n",
    "    test_y = test_data['Active'].to_numpy()\n",
    "    stats = eval_matrices(model, test_x, test_y)\n",
    "\n",
    "    print(\"surroseq\")\n",
    "    data_path = \"datasets/surroseq.csv\"\n",
    "    test_data = pd.read_csv(data_path)\n",
    "    test_x = one_hot_features(test_data)\n",
    "    test_y = test_data['Active'].to_numpy()\n",
    "    stats = eval_matrices(model, test_x, test_y)\n",
    "\n",
    "    print(\"guideseq\")\n",
    "    data_path = \"datasets/guideseq.csv\"\n",
    "    test_data = pd.read_csv(data_path)\n",
    "    test_x = one_hot_features(test_data)\n",
    "    test_y = test_data['Active'].to_numpy()\n",
    "    stats = eval_matrices(model, test_x, test_y)\n",
    "\n",
    "    print(\"ttiss\")\n",
    "    data_path = \"datasets/ttiss.csv\"\n",
    "    test_data = pd.read_csv(data_path)\n",
    "    test_x = one_hot_features(test_data)\n",
    "    test_y = test_data['Active'].to_numpy()\n",
    "    stats = eval_matrices(model, test_x, test_y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c358a61b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:40.821148Z",
     "iopub.status.busy": "2024-12-07T06:53:40.820907Z",
     "iopub.status.idle": "2024-12-07T06:53:40.826616Z",
     "shell.execute_reply": "2024-12-07T06:53:40.825941Z"
    },
    "papermill": {
     "duration": 0.011029,
     "end_time": "2024-12-07T06:53:40.828098",
     "exception": false,
     "start_time": "2024-12-07T06:53:40.817069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_model(model, train_loader, optimizer, scheduler, criterion, device, num_epochs):\n",
    "    model = model.to(device)\n",
    "    history = {'train_loss': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Training loop\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Loss tracking\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Average loss for the epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f}\")\n",
    "        scheduler.step()\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632fd49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:40.835204Z",
     "iopub.status.busy": "2024-12-07T06:53:40.834962Z",
     "iopub.status.idle": "2024-12-07T06:53:40.840710Z",
     "shell.execute_reply": "2024-12-07T06:53:40.840029Z"
    },
    "papermill": {
     "duration": 0.011065,
     "end_time": "2024-12-07T06:53:40.842270",
     "exception": false,
     "start_time": "2024-12-07T06:53:40.831205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainer(config, train_x, train_y):\n",
    "    seed = 12345\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    train_dataset = TrainerDataset(train_x, train_y)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    model = CRISPRTransformerModel(config)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    class_weights = torch.tensor([1.0, config['pos_weight']]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    trained_model, history = train_model(model, train_loader, optimizer, scheduler, criterion, device, config['epochs'])\n",
    "    return trained_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072c94c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:53:40.849704Z",
     "iopub.status.busy": "2024-12-07T06:53:40.849203Z",
     "iopub.status.idle": "2024-12-07T06:55:10.295968Z",
     "shell.execute_reply": "2024-12-07T06:55:10.295215Z"
    },
    "papermill": {
     "duration": 89.452733,
     "end_time": "2024-12-07T06:55:10.298197",
     "exception": false,
     "start_time": "2024-12-07T06:53:40.845464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating One hot encoding features...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data_path = \"datasets/changeseq_siteseq.csv\"\n",
    "train_data = pd.read_csv(data_path)\n",
    "train_x = one_hot_features(train_data)\n",
    "train_y = train_data['Active'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4ee99c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T06:55:10.306521Z",
     "iopub.status.busy": "2024-12-07T06:55:10.306207Z",
     "iopub.status.idle": "2024-12-07T08:09:37.603472Z",
     "shell.execute_reply": "2024-12-07T08:09:37.602701Z"
    },
    "papermill": {
     "duration": 4467.30354,
     "end_time": "2024-12-07T08:09:37.605514",
     "exception": false,
     "start_time": "2024-12-07T06:55:10.301974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.2372\n",
      "Epoch 2/50 | Train Loss: 0.1883\n",
      "Epoch 3/50 | Train Loss: 0.1733\n",
      "Epoch 4/50 | Train Loss: 0.1625\n",
      "Epoch 5/50 | Train Loss: 0.1537\n",
      "Epoch 6/50 | Train Loss: 0.1448\n",
      "Epoch 7/50 | Train Loss: 0.1364\n",
      "Epoch 8/50 | Train Loss: 0.1310\n",
      "Epoch 9/50 | Train Loss: 0.1250\n",
      "Epoch 10/50 | Train Loss: 0.1224\n",
      "Epoch 11/50 | Train Loss: 0.1594\n",
      "Epoch 12/50 | Train Loss: 0.1607\n",
      "Epoch 13/50 | Train Loss: 0.1605\n",
      "Epoch 14/50 | Train Loss: 0.1563\n",
      "Epoch 15/50 | Train Loss: 0.1552\n",
      "Epoch 16/50 | Train Loss: 0.1551\n",
      "Epoch 17/50 | Train Loss: 0.1498\n",
      "Epoch 18/50 | Train Loss: 0.1499\n",
      "Epoch 19/50 | Train Loss: 0.1459\n",
      "Epoch 20/50 | Train Loss: 0.1387\n",
      "Epoch 21/50 | Train Loss: 0.1350\n",
      "Epoch 22/50 | Train Loss: 0.1312\n",
      "Epoch 23/50 | Train Loss: 0.1280\n",
      "Epoch 24/50 | Train Loss: 0.1237\n",
      "Epoch 25/50 | Train Loss: 0.1209\n",
      "Epoch 26/50 | Train Loss: 0.1166\n",
      "Epoch 27/50 | Train Loss: 0.1143\n",
      "Epoch 28/50 | Train Loss: 0.1122\n",
      "Epoch 29/50 | Train Loss: 0.1116\n",
      "Epoch 30/50 | Train Loss: 0.1109\n",
      "Epoch 31/50 | Train Loss: 0.1533\n",
      "Epoch 32/50 | Train Loss: 0.1542\n",
      "Epoch 33/50 | Train Loss: 0.1570\n",
      "Epoch 34/50 | Train Loss: 0.1577\n",
      "Epoch 35/50 | Train Loss: 0.1597\n",
      "Epoch 36/50 | Train Loss: 0.1572\n",
      "Epoch 37/50 | Train Loss: 0.1557\n",
      "Epoch 38/50 | Train Loss: 0.1560\n",
      "Epoch 39/50 | Train Loss: 0.1595\n",
      "Epoch 40/50 | Train Loss: 0.1526\n",
      "Epoch 41/50 | Train Loss: 0.1530\n",
      "Epoch 42/50 | Train Loss: 0.1583\n",
      "Epoch 43/50 | Train Loss: 0.1520\n",
      "Epoch 44/50 | Train Loss: 0.1549\n",
      "Epoch 45/50 | Train Loss: 0.1494\n",
      "Epoch 46/50 | Train Loss: 0.1461\n",
      "Epoch 47/50 | Train Loss: 0.1443\n",
      "Epoch 48/50 | Train Loss: 0.1425\n",
      "Epoch 49/50 | Train Loss: 0.1439\n",
      "Epoch 50/50 | Train Loss: 0.1367\n",
      "Circleseq\n",
      "Generating One hot encoding features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1950465590.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = [torch.nn.functional.softmax(r) for r in results]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9772\n",
      "Precision: 0.5261\n",
      "Recall: 0.6930\n",
      "F1 Score: 0.5981\n",
      "ROC: 0.9706498645845513\n",
      "PR AUC: 0.6366\n",
      "surroseq\n",
      "Generating One hot encoding features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1950465590.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = [torch.nn.functional.softmax(r) for r in results]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6306\n",
      "Precision: 0.1972\n",
      "Recall: 0.6752\n",
      "F1 Score: 0.3053\n",
      "ROC: 0.717570604726568\n",
      "PR AUC: 0.4767\n",
      "guideseq\n",
      "Generating One hot encoding features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1950465590.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = [torch.nn.functional.softmax(r) for r in results]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9795\n",
      "Precision: 0.0549\n",
      "Recall: 0.9649\n",
      "F1 Score: 0.1039\n",
      "ROC: 0.9944579290851235\n",
      "PR AUC: 0.5227\n",
      "ttiss\n",
      "Generating One hot encoding features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1950465590.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = [torch.nn.functional.softmax(r) for r in results]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9902\n",
      "Precision: 0.0977\n",
      "Recall: 0.7427\n",
      "F1 Score: 0.1727\n",
      "ROC: 0.9730377878558901\n",
      "PR AUC: 0.4207\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_layers': 2, \n",
    "    'num_heads': 4, \n",
    "    'number_hidder_layers': 2, \n",
    "    'dropout_prob': 0.2, \n",
    "    'batch_size': 128, \n",
    "    'epochs': 50, \n",
    "    'learning_rate': 0.001, \n",
    "    'pos_weight': 30, \n",
    "    'attn': False\n",
    "}\n",
    "model, history = trainer(config, train_x, train_y)\n",
    "eval(model)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4146873,
     "sourceId": 10060955,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4566.247917,
   "end_time": "2024-12-07T08:09:39.535690",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-07T06:53:33.287773",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
